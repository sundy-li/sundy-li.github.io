[{"categories":["database"],"content":"Context Snowflake IPO 大火之后，大家都开始慢慢了解到这个完全基于云计算设计的新式数据仓库。 Snowflake 的核心在于基于云端近似无限的计算存储资源，提供了极致弹性且高效的计算引擎 并且搭配 低成本且同样弹性伸缩的存储，大大减少了用户的心智负担和数据的计算存储成本，让用户更加专注于发挥数据对业务的价值。对于传统的数据仓库来说，Snowflake 就像一块降维打击的 二向箔。 在业务增长的过程中，客户的数据持续增长，从而导致单表变大，对大表的高效分析依赖于一套高性能的查询引擎。Snowflake 有一个非常核心的功能： Auto Clustering, 极大地提升了大表的查询效率。 我们这里主要探索下，Snowflake 的 Auto Clustering 功能是如何设计的。 ","date":"2022-03-26","objectID":"/posts/%E6%8E%A2%E7%B4%A2snowflake-auto-clustering/:1:0","tags":["Snowflake","database","Cloud-native"],"title":"探索Snowflake auto clustering 设计","uri":"/posts/%E6%8E%A2%E7%B4%A2snowflake-auto-clustering/"},{"categories":["database"],"content":"什么是 Auto Clustering 注意: 这里的 Clustering 是指分组、聚类 的意思，注意不要理解为分布式、集群等概念。 Snowflake 的 Clustering 功能 和传统数据的 Partition 分区功能类似。但在传统的数据库系统中，大多依赖一些静态的分区规则来实现数据的物理隔离，如按时间，按用户特征hash等等，在hive等数据仓库中，最常见到的还是按照时间分区。当一个带有分区字段相关的查询过来的时候，分区的裁剪可以直接忽略掉不匹配的数据，这样就可以大大减少了数据的读取和计算量，从而提高查询性能。 静态分区用法非常简单，比如在Hive中： -- Create Partition ALTERTABLEtable_nameADDPARTITION(dt='2020-03-26',hour='08')location'/path/table/20200326/08';-- Then load data into the partition 但它有以下一些缺点： 开发人员在建表的时候必须知道数据的分布情况和将来面对的查询模式，增加了用户的心智负担。 静态分区的规则是固定的，但数据却是随时间在变化的，比如业务持续增长过程中，按天分区的表 新的分区会变大，从而导致分区分布不均匀。 Snowflake 在设计中 完全抛弃了 传统的静态Partition 的概念，而提出了 Auto Clustering 的新设计。简而言之，用户再也不用关心我的表是如何如何分区了，用户只管插入和查询就是了，数据分组，性能优化我会自动做!!! How ？ ","date":"2022-03-26","objectID":"/posts/%E6%8E%A2%E7%B4%A2snowflake-auto-clustering/:2:0","tags":["Snowflake","database","Cloud-native"],"title":"探索Snowflake auto clustering 设计","uri":"/posts/%E6%8E%A2%E7%B4%A2snowflake-auto-clustering/"},{"categories":["database"],"content":"Micro Partition (微分区) 虽然抛弃了静态分区，但snowflake 里面还是有 Micro-Partition 和 Cluster Key 的概念。 Cluster Key 是排序键，可以由多个字段组成，类似ClickHouse 的 Order Key。 Micro-Partition 是数据的基本组成单元，一个表的数据是由多个 Micro-Partitions 组成的。 我们可以将它理解为一个物理文件，这个物理文件限制在 50MB-500MB 的大小（未压缩），物理文件采用了列式存储，不同的列存储在不同的连续空间内。Snowflake 会存储 Micro-Partition 的信息到元数据服务中，方便查询的时候通过元数据索引进行剪枝，如： 每个列的区间索引, 最大值最小值等 (ZoneMap index） 列分布的直方图信息 其他.. 注： 鉴于Micro-Partition 的大小可能到500MB, 个人认为 Micro-Partition 的内部按道理应当划分类似Parquet的pages（clickhouse的mrk)，每个page有自己的索引，这样就可以在 Micro-Partition内部提高查询过滤的性能。不过看 Snowflake 目前的设计来说，微分区级别索引是最小粒度了，暂时没有微分区内部pages索引了，具体原因未知，文章末尾会提到个人的一些猜测。 ","date":"2022-03-26","objectID":"/posts/%E6%8E%A2%E7%B4%A2snowflake-auto-clustering/:3:0","tags":["Snowflake","database","Cloud-native"],"title":"探索Snowflake auto clustering 设计","uri":"/posts/%E6%8E%A2%E7%B4%A2snowflake-auto-clustering/"},{"categories":["database"],"content":"Clustered Tables 数据表建立后，默认数据是自然序，自然序意味着我们没有做任何处理，数据就按照流入的顺序排列，此时表处于 Unclustered 状态。当 表经历了 Clustering后，每个 Micro-Partitions 会按照指定的key进行排序, 可以理解为给表加了一个排序键，此时表处于 Clustered 状态。 上图来自Snowflake文档。 Clustered 的主要目的是让大部分的查询能高效的裁剪数据，避免不需要的IO读取和计算。 举个例子： selectname,countryfromt1wheretype=2anddate='11/2';在原始的数据排列中（自然序），上面的SQL会扫描到 4个 微分区。而在 Clustered 状态下，数据已经按照 Cluster Key -\u003e (date, type) 进行排序，所以只会扫描到 1个 微分区，其他的微分区都被引擎结合了存储在元数据的索引进行了裁剪过滤。 ","date":"2022-03-26","objectID":"/posts/%E6%8E%A2%E7%B4%A2snowflake-auto-clustering/:4:0","tags":["Snowflake","database","Cloud-native"],"title":"探索Snowflake auto clustering 设计","uri":"/posts/%E6%8E%A2%E7%B4%A2snowflake-auto-clustering/"},{"categories":["database"],"content":"怎样让表达到 Well-Clustered ？ 一般来说，大表不会是静态的数据，大多会是时序数据，也就是说说数据不断地实时流入。因此，对整个表级别的数据全排序是非常不现实的，不仅代价较高，实时流入的数据也会影响全排序结果。另外一种方法是只对流入的数据进行排序，这样虽然新数据有比较好的顺序，但随着数据在不断地流入，数据整体的顺序会逐渐趋于混乱。 结合上面的分析，一个表如果能达到 Well-Clustered（表数据的整体有序度高), 这样查询才能高效。在这个前提下，还需要保证 “新数据能实时高效流入“（确保DML高效），两者之间存在一个平衡点， Snowflake 的做法是 优先保证新数据能实时高效流入，新数据是不需要对数据整体的有序度 “负责”，因为新数据相比历史数据来说量级较小，影响的有序度也较小，它只需保证局部有序就行了（确保新数据查询也能高效）。新数据在后台会异步进行合并，保证 ”表数据的整体有序度高“，也就是说 数据的整体有序是一个渐进的过程，而不是整体绝对有序的。 ","date":"2022-03-26","objectID":"/posts/%E6%8E%A2%E7%B4%A2snowflake-auto-clustering/:5:0","tags":["Snowflake","database","Cloud-native"],"title":"探索Snowflake auto clustering 设计","uri":"/posts/%E6%8E%A2%E7%B4%A2snowflake-auto-clustering/"},{"categories":["database"],"content":"如何衡量 Well-Clustered ？ Snowflake 引入了几个主要的指标来衡量表的 Well-Clustered 程度： Overlaps: 在一个Range范围内，有多少个 Micro-Partitions 有重叠 Depth: 在一个数据点中，有多少个 Micro-Partitions 有重叠 上面的图从上到下展示了四种 表 Cluster 的状态， 第一种情况是4个 微分区 完全重叠，这种情况是最糟糕的，因为它没有任何区分度，命中了A-Z这个Range的查询会不可避免地扫描四个分区。 随着Depth指标的下降，表中微分区变得逐渐离散， Overlaps 指标也在下降，表也逐渐变得更加 Well-Clustered。 当然，在实际的表分布中，微分区的分布要达到最下面那样规整（全局有序）是不现实的，因为所需要的开销太大了。 levels： 微分区所属的级别 为了减少写放大，微分区的合并策略和 LSM-tree 类似，微分区在后台不断地合并后形成新的微分区，每次合并完成后，微分区的 Level 值就会自增（clickhouse也有类似的 Part 合并逻辑），所以 Level 表示的就是微分区经历过的合并次数（用来衡量经历过的合并成本）。新数据流入的微分区 Level 默认是0，Level 越低的微分区中，Overlaps 和 Depth 指标相对来说会越高，在不断合并的过程中，微分区变得越来越离散，表也变得更加 Well-Clustered。 注意： 微分区只会和同Level的微分区合并， Level 存在最大值，避免写放大太严重。 ","date":"2022-03-26","objectID":"/posts/%E6%8E%A2%E7%B4%A2snowflake-auto-clustering/:6:0","tags":["Snowflake","database","Cloud-native"],"title":"探索Snowflake auto clustering 设计","uri":"/posts/%E6%8E%A2%E7%B4%A2snowflake-auto-clustering/"},{"categories":["database"],"content":"Auto Clustering 是如何进行的？ Auto Clustering 主要分为两大任务: Part-Selection 任务 Part-Merge 任务 这块和ClickHouse 的逻辑很类似，但明显的区别是 Snowflake 对云实在太偏爱了，上面所有的任务都可以在云端拉起独立的进程进行，而不需要占用用户的计算资源，并且这两个进程也是微服务化的，可以按需弹性伸缩。 ","date":"2022-03-26","objectID":"/posts/%E6%8E%A2%E7%B4%A2snowflake-auto-clustering/:7:0","tags":["Snowflake","database","Cloud-native"],"title":"探索Snowflake auto clustering 设计","uri":"/posts/%E6%8E%A2%E7%B4%A2snowflake-auto-clustering/"},{"categories":["database"],"content":"Part-Selection 任务 Selection 任务会从某个 Level 中选择出微分区列表集合，选择的策略是启发式的。 上面提到的2个指标可以构建一个启发式的算法： Level 低的优先级的微分区被选择的优先级高，因此新流入的数据能有较高优先级合并到下个Level，Level越高的微分区除非在有充足的资源情况下，不会被合并。 Depth 高的微分区被选择的优先级高。 因此Selection的目标就是降低 Level 中微分区的平均深度，AvgDepth。 这里引入一个AvgDepth的计算逻辑： 下面四个微分区的情况下： 我们对每个端点进行分析，如果没有overlap，depth忽略，因为depth的目的就是衡量overflap的程度，引入depth = 0会导致数据有偏差，此时depth表示一个端点覆盖了几个分区。 最终的计算方式是： AvgDepth = Sum(DepthOfOverflapPoint) / OverflapPointsCnt Snowflake 没有公开具体的Selection算法，不过大概是 Level + AvgDepth 结合的一个公式进行排序，我们假设它是以 每个Level的AvgDepth排序选择某个Level，然后去顺序遍历此Level下的所有端点，超过了AvgDepth的连续端点会被选择作为Range。 上面的曲线是如何构建的 ？ 横轴对应的就是Key的Range， 纵轴表示 Depth，计算方式大概是：遍历所有的微分区，将微分区的 Range 的 Depth 进行求和 （即上面的 DepthOfOverflapPoint )，得出对应端点的 Y 值 （这里应该可以用差分数组的数据结构进行优化） 选择的策略是什么 ？ 上图是选择了两个微分区列表的集合示例，选择的方式是顺序遍历所有的端点，如果端点的Depth超过了AvgDepth，就会被选择，连续选择的端点构成一个Range。 为什么不直接选最高的Depth ？ 可以发现最高点 Depth 虽然最高，但 覆盖的Range 变窄，这样导致选择的微分区数量太小，对降低AvgDepth的影响较少。 选择的结果是什么 ？ 看有多少个符合条件的波峰，上图是两个符合条件的波峰，这两个波峰互不重合，可以作为选择的结果集合，集合中内包含了微分区的 batches。 ClickHouse 中也有类似的选择策略算法，建议读者有时间也可以去了解下。 ","date":"2022-03-26","objectID":"/posts/%E6%8E%A2%E7%B4%A2snowflake-auto-clustering/:7:1","tags":["Snowflake","database","Cloud-native"],"title":"探索Snowflake auto clustering 设计","uri":"/posts/%E6%8E%A2%E7%B4%A2snowflake-auto-clustering/"},{"categories":["database"],"content":"Part-Merge 任务 接收到Selection的列表后，Part-Merge 可以独立地进行微分区的排序和合并，类似一个归并排序的过程。合并后的微分区就是一个全局有序的大微分区了。值得一提的是，合并后的分区如果超过了500MB的阈值上限，就会被分裂成更小的微分区，这和ClickHouse 存储一个大的分区文件 是不同的。 我猜测可能是： Snowflake 和 ClickHouse不一样， 它不再维护微分区内部的稀疏索引， 稀疏索引的最小粒度就是微分区。 在云端对象存储中，读取整个微分区 比 在微分区内部进行部分Range 虽然IO开销稍大，但差异不会太大， 而且对象存储一般都有对象级别的Cache，所以Snowflake的元数据只存储了微分区粒度的索引。 ","date":"2022-03-26","objectID":"/posts/%E6%8E%A2%E7%B4%A2snowflake-auto-clustering/:7:2","tags":["Snowflake","database","Cloud-native"],"title":"探索Snowflake auto clustering 设计","uri":"/posts/%E6%8E%A2%E7%B4%A2snowflake-auto-clustering/"},{"categories":["database"],"content":"其他 系统函数： system$clustering_depth: 返回表平均的ClusteringDepth，可以指定 columns 参数 system$clustering_information: 返回表相关clustering 信息，包含 average_overlaps, average_depth, partition_depth_histogram 等 锁优化 Selection 和 Merge 进行不会对原始数据持有锁，也就是说在这两个过程中都不会卡主用户数据的查询和插入。这个优化其实很简单，就是在合并之后，持有对 合并涉及的微分区的锁，然后标记下新的微分区为Active状态，老的微分区为Outdate状态，异步GC删除，一些标志位的更新，涉及锁开销可以忽略不计。 自动合并服务 就是上面讲的 Selection 和 Merge 做成两个独立的服务异步运行。 Snowflake 旧版本提供了 手动 Cluster，后面废弃了，我猜测更多是让用户使用便捷，不用去Care Clustering这层操作，因为这些事情后台会自动做了，不当地频繁clustering反而增加了不必要的开销。 收费 虽然clustering没有用客户的计算资源，但收费还是要算在用户头上的，在 Billing \u0026 Usage 页面可以看到对应的计费情况。 相关配图，参考文章来源： tables-clustering-micropartitions Automatic Clustering at Snowflake How does automatic clustering work in Snowflake zero-to-snowflake-automated-clustering-in-snowflake ","date":"2022-03-26","objectID":"/posts/%E6%8E%A2%E7%B4%A2snowflake-auto-clustering/:8:0","tags":["Snowflake","database","Cloud-native"],"title":"探索Snowflake auto clustering 设计","uri":"/posts/%E6%8E%A2%E7%B4%A2snowflake-auto-clustering/"},{"categories":["database","databend"],"content":" 春节期间花了前后一个月时间终于重构完了databend的datavalues模块，本文将介绍在新的datavalues系统中是如何使用类型体操的。 ","date":"2022-02-25","objectID":"/posts/%E7%B1%BB%E5%9E%8B%E4%BD%93%E6%93%8D%E5%9C%A8databend%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/:0:0","tags":null,"title":"类型体操在databend中的应用","uri":"/posts/%E7%B1%BB%E5%9E%8B%E4%BD%93%E6%93%8D%E5%9C%A8databend%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/"},{"categories":["database","databend"],"content":"Context 在旧版本的datavalues模块中，我们要编写函数通常需要写很多冗余的代码 加上各种宏结合，代码看起来非常繁琐，比如 in函数的实现： 除了上面的例子，缺点还有： Column是一个enum类型，包含Constant 和 Series(一个ArrayTrait，可以理解为 Arc\u003cdyn Array\u003e). pub enum DataColumn { // Array of values. Array(Series), // A Single value. Constant(DataValue, usize), } Constant 列在列式系统中是非常有必要的，它表示列是一个常量值，比如 number + 3, 3 就是一个常量列，向量化计算中它会和number列中对应行位置数值进行相加。 常量列可以在runtime计算中节省内存分配回收的开销，在一些特殊的算子中，常量列可以提高不少性能，如 rem by scalar。 为此，我们旧版本的函数计算通常都需要每个地方加入各种 match 来匹配常量列的情况，这样会导致代码的繁琐，而且还会导致代码的可读性差。如果函数的参数非常多，会导致 match 满天飞的情况出现，比如 export_set函数。 常量列虽然也可以通过 to_array 方法物化成普通列，物化意味着内存的开销，虽然提高了可读性，但影响了性能。 无法通过 scalar 函数来自动形成向量化的函数： 比如 comparison 函数，我们需要为 10个基础类型 + bool 类型 + String 类型的 列运用此函数。 即使我们有一种非常精简的标量函数实现， fn cmp(a: S, b: S) {a.cmp(b)}，也不能自动形成向量化的函数。 根本的原因在于没有将列类型和标量类型在编译期间就进行绑定。 ","date":"2022-02-25","objectID":"/posts/%E7%B1%BB%E5%9E%8B%E4%BD%93%E6%93%8D%E5%9C%A8databend%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/:1:0","tags":null,"title":"类型体操在databend中的应用","uri":"/posts/%E7%B1%BB%E5%9E%8B%E4%BD%93%E6%93%8D%E5%9C%A8databend%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/"},{"categories":["database","databend"],"content":"尝试 在ClickHouse 或者 Velox等c++ 项目中，这个绑定用一些template技巧就可以很好的解决，但在Rust中，我们需要开启不稳定的GAT特性，既然要绑定的话，那一个雏形大概是： ScalarColumn 的定义 pub trait ScalarColumn: Column + Send + Sync + Sized + 'static { type OwnedItem: Scalar\u003cColumnType = Self\u003e; fn value_at(\u0026self, index: usize) -\u003e Self::OwnedItem; } Scalar 类型的定义： pub trait Scalar: 'static + Sized + Default + Any { type ColumnType: ScalarColumn\u003cOwnedItem = Self\u003e; } 然后我们为 10个基础类型 + bool 类型 + String 类型 都加上 Scalar的实现，此处省略一堆macros。 理想很美满，但现实非常悲惨。 value_at 返回了对应索引的Scalar值，如果是 10个基础类型， 我们可以返回引用或者值， 如果是 String 类型, 我们返回值意味着每次访问都有一次内存copy，这在列式计算中是开销是非常大的，于是我决定修改 value_at方法，统一返回引用： fn value_at(\u0026self, index: usize) -\u003e \u0026Self::OwnedItem; 但 Boolean 类型，我们是无法返回引用的，因为在内存模型中， Boolean 列是一个bitmap实现，没有Owner到boolean值，value_at方法必须返回值。 要解决这个问题，我想到了两个思路： 一种是通过unsafe + 锁的方式往这个 BooleanColumn 里面去物化一个 Vec\u003cbool\u003e，这样就可以返回引用了, 这个unsafe 略显trick。 第二种是将 BooleanColumn 直接用 Vec\u003cu8\u003e存储，但这样和arrow转换内存数据时会有额外的内存copy开销。 为此陷入了一些误区，让组里的同学也帮忙想想好的解决思路，但一直没有理想的解决方案。 ","date":"2022-02-25","objectID":"/posts/%E7%B1%BB%E5%9E%8B%E4%BD%93%E6%93%8D%E5%9C%A8databend%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/:2:0","tags":null,"title":"类型体操在databend中的应用","uri":"/posts/%E7%B1%BB%E5%9E%8B%E4%BD%93%E6%93%8D%E5%9C%A8databend%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/"},{"categories":["database","databend"],"content":"巧遇type-exercise 此事搁置后不久，在github刷到了迟先生开源的 类型体操，犹如醍醐灌顶，原来 Rust 还可以这么玩，我怎么没有想到可以绑定 一种引用类型呢？ 如果读者没有看过迟先生类型体操项目，强烈推荐去阅读下，同时还有配套知乎专栏 服务。 下面介绍下 类型体操 在databend中是如何运用的。 ","date":"2022-02-25","objectID":"/posts/%E7%B1%BB%E5%9E%8B%E4%BD%93%E6%93%8D%E5%9C%A8databend%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/:3:0","tags":null,"title":"类型体操在databend中的应用","uri":"/posts/%E7%B1%BB%E5%9E%8B%E4%BD%93%E6%93%8D%E5%9C%A8databend%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/"},{"categories":["database","databend"],"content":"Databend 应用类型体操 和开源的 type-exercise 稍有不同，我们的中心是 Scalar 类型，而不是 Column 类型。 详见代码 ","date":"2022-02-25","objectID":"/posts/%E7%B1%BB%E5%9E%8B%E4%BD%93%E6%93%8D%E5%9C%A8databend%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/:4:0","tags":null,"title":"类型体操在databend中的应用","uri":"/posts/%E7%B1%BB%E5%9E%8B%E4%BD%93%E6%93%8D%E5%9C%A8databend%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/"},{"categories":["database","databend"],"content":"实现 Scalar, ScalarRef， ScalarColumn 的定义和开源版本差不多，这里不再赘述。 这里着重讲讲一些不同之处： ScalarColumn 无需考虑nullable的存在， nullable 我们在外层会进行统一处理（bitmap取与操作），特殊情况我们可以用 后面讲到的 ScalarViewer 来解决。 由于不需要考虑nullable，column生成的迭代器可以利用 slice.iter(),省去了各种bound check的开销，并且无需option封装，省去了分支预测的开销，便于循环中计算的pipeline计算或编译器的自动优化。 Scalar 和 ScalarRef 以及 ScalarColumn 有绑定，ScalarRef 和 ScalarColumn 也有绑定， 但是我们需要告诉编译器ScalarColumn中的ScalarRef 和 Scalar中的ScalarRef 是同一个ScalarRef （有点绕），因此我们加了一个额外的 限定 pubtraitScalar: 'static +Sized+Default+Any+wherefor\u003c'a\u003eSelf::ColumnType: ScalarColumn\u003cRefItem\u003c'a\u003e=Self::RefType\u003c'a\u003e\u003e+{这样一来，我们绑定在ScalarColumn上的类型和绑定在Scalar上的类型就已经产生了级联联动。 以Scalar为中心的 UnaryExpression 实现: ScalarUnaryFunction 类型： pubtraitScalarUnaryFunction\u003cL: Scalar,O: Scalar\u003e{fn eval(\u0026self,l: L::RefType\u003c'_\u003e,_ctx: \u0026mutEvalContext)-\u003e O;}/// Blanket implementation for all binary expression functions impl\u003cL: Scalar,O: Scalar,F\u003eScalarUnaryFunction\u003cL,O\u003eforFwhereF: Fn(L::RefType\u003c'_\u003e,\u0026mutEvalContext)-\u003e O{fn eval(\u0026self,i1: L::RefType\u003c'_\u003e,ctx: \u0026mutEvalContext)-\u003e O{self(i1,ctx)}}ScalarUnaryExpression: /// A common struct to caculate Unary expression scalar op. #[derive(Clone)]pubstruct ScalarUnaryExpression\u003cL: Scalar,O: Scalar,F\u003e{f: F,_phantom: PhantomData\u003c(L,O)\u003e,}impl\u003c'a,L: Scalar,O: Scalar,F\u003eScalarUnaryExpression\u003cL,O,F\u003ewhereF: ScalarUnaryFunction\u003cL,O\u003e{/// Create a Unary expression from generic columns and a lambda function. pubfn new(f: F)-\u003e Self{Self{f,_phantom: PhantomData,}}/// Evaluate the expression with the given array. pubfn eval(\u0026self,l: \u0026'a ColumnRef,ctx: \u0026mutEvalContext,)-\u003e Result\u003c\u003cOasScalar\u003e::ColumnType\u003e{letleft=Series::check_get_scalar::\u003cL\u003e(l)?;letit=left.scalar_iter().map(|a|(self.f).eval(a,ctx));letresult=\u003cOasScalar\u003e::ColumnType::from_owned_iterator(it);ifletSome(error)=ctx.error.take(){returnErr(error);}Ok(result)}}上面的 EvalContext 是为了存储计算过程中可能出现的Error， 借助 ScalarUnaryExpression的封装， 我们就可以自动将标量函数的实现转为向量化的实现了，示例： 向量化hash函数: fn hash_func\u003cH,S,O\u003e(l: S::RefType\u003c'_\u003e,_ctx: \u0026mutEvalContext)-\u003e OwhereS: Scalar,O: Scalar+FromPrimitive,H: Hasher+Default,for\u003c'a\u003e\u003cSasScalar\u003e::RefType\u003c'a\u003e: DFHash,{letmuth=H::default();l.hash(\u0026muth);O::from_u64(h.finish()).unwrap()}...fn eval(\u0026self,columns: \u0026common_datavalues::ColumnsWithField,_input_rows: usize,)-\u003e Result\u003ccommon_datavalues::ColumnRef\u003e{with_match_scalar_types_error!(columns[0].data_type().data_type_id().to_physical_type(),|$S|{letunary=ScalarUnaryExpression::\u003c$S,R,_\u003e::new(hash_func::\u003cH,$S,R\u003e);letcol=unary.eval(columns[0].column(),\u0026mutEvalContext::default())?;Ok(Arc::new(col))})}同理，我们可以实现 以 Scalar 为中心的 ScalarBinaryExpression, 由于有Constant的存在，实现稍显复杂，因为需要match 四种情况， 不过我们都封装在 ScalarBinaryExpression 内部，函数实现无需重复match，示例： #[test]fn test_binary_contains(){//create two string columns struct Contains{}implScalarBinaryFunction\u003cVu8,Vu8,bool\u003eforContains{fn eval(\u0026self,a: \u0026'_ [u8],b: \u0026'_ [u8],_ctx: \u0026mutEvalContext)-\u003e bool {a.windows(b.len()).any(|window|window==b)}}letbinary_expression=ScalarBinaryExpression::\u003cVec\u003cu8\u003e,Vec\u003cu8\u003e,bool,_\u003e::new(Contains{});for_in0..10{letl=Series::from_data(vec![\"11\",\"22\",\"33\"]);letr=Series::from_data(vec![\"1\",\"2\",\"43\"]);letexpected=Series::from_data(vec![true,true,false]);letresult=binary_expression.eval(\u0026l,\u0026r,\u0026mutEvalContext::default()).unwrap();letresult=Arc::new(result)asColumnRef;assert!(result==expected);}}","date":"2022-02-25","objectID":"/posts/%E7%B1%BB%E5%9E%8B%E4%BD%93%E6%93%8D%E5%9C%A8databend%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/:5:0","tags":null,"title":"类型体操在databend中的应用","uri":"/posts/%E7%B1%BB%E5%9E%8B%E4%BD%93%E6%93%8D%E5%9C%A8databend%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/"},{"categories":["database","databend"],"content":"进阶 虽然有 Unary 和 Binary 两种Expression的封装， 不过有的函数参数众多，单目和双目 表达式都无法覆盖。在这种情况下，我们仍然无法避免对Constant 情况 进行match，这里我们对类型体操进行了扩充，引入了 ScalarViewer的概念，它可以处理 nullable 和 constant 两种特殊的column，并且提供统一的API封装。 ScalarViewer 和 Scalar 可以相互绑定，它还可以绑定一个迭代器，同时提供按索引取值和判断null的操作。 pubtraitScalarViewer\u003c'a\u003e: Clone +Sized{type ScalarItem: Scalar\u003cViewer\u003c'a\u003e=Self\u003e;type Iterator: Iterator\u003cItem=\u003cSelf::ScalarItemasScalar\u003e::RefType\u003c'a\u003e\u003e+ExactSizeIterator+TrustedLen;fn try_create(col: \u0026'a ColumnRef)-\u003e Result\u003cSelf\u003e;fn value_at(\u0026self,index: usize)-\u003e \u003cSelf::ScalarItemasScalar\u003e::RefType\u003c'a\u003e;fn valid_at(\u0026self,i: usize)-\u003e bool;/// len is implemented in ExactSizeIterator fn size(\u0026self)-\u003e usize;fn null_at(\u0026self,i: usize)-\u003e bool {!self.valid_at(i)}fn is_empty(\u0026self)-\u003e bool {self.size()==0}fn iter(\u0026self)-\u003e Self::Iterator;}一个 ScalarViewer的实现： #[derive(Clone)]pubstruct PrimitiveViewer\u003c'a,T: PrimitiveType\u003e{pub(crate)values: \u0026'a [T],// for not nullable column, it's 0. we only need keep one sign bit to tell `null_at` that it's not null. // for nullable column, it's usize::max, validity will be cloned from nullable column. pub(crate)null_mask: usize,// for const column, it's 0, `value` function will fetch the first value of the column. // for not const column, it's usize::max, `value` function will fetch the value of the row in the column. pub(crate)non_const_mask: usize,pub(crate)size: usize,pub(crate)pos: usize,pub(crate)validity: Bitmap,}这里引入了两种 位操作掩码的技巧: null_mask, 如果column是非nullable或者constant的，那么 null_mask 就是0，如果是nullable的，那么 null_mask 就是 usize::max non_const_mask: 如果column是constant的，那么 non_const_mask 就是0，如果是非constant的，那么 non_const_mask 就是 usize::max 有了两个掩码后，我们可以运用位操作来减少一个if判断的开销: #[inline]fn value_at(\u0026self,index: usize)-\u003e T{self.values[index\u0026self.non_const_mask]}#[inline]fn valid_at(\u0026self,i: usize)-\u003e bool {unsafe{self.validity.get_bit_unchecked(i\u0026self.null_mask)}} Viewer迭代器： Viewer迭代器的实现就是将 Viewer 的index置为0，然后clone一次 fn iter(\u0026self)-\u003e Self{letmutres=self.clone();res.pos=0;res}// 实现 Iterator trait fn next(\u0026mutself)-\u003e Option\u003cSelf::Item\u003e{ifself.pos\u003e=self.size{returnNone;}letold=self.pos;self.pos+=1;Some(unsafe{*self.values.as_ptr().add(old\u0026self.non_const_mask)})} 自定义迭代器一定不要忘记实现 TrustedLen， 提高迭代器遍历生成Vec的性能: unsafeimpl\u003c'a,T\u003eTrustedLenforPrimitiveViewer\u003c'a,T\u003ewhereT: Scalar\u003cViewer\u003c'a\u003e=Self\u003e+PrimitiveType,T: ScalarRef\u003c'a,ScalarType=T\u003e,T: Scalar\u003cRefType\u003c'a\u003e=T\u003e,{}impl\u003c'a,T\u003eExactSizeIteratorforPrimitiveViewer\u003c'a,T\u003ewhereT: Scalar\u003cViewer\u003c'a\u003e=Self\u003e+PrimitiveType,T: ScalarRef\u003c'a,ScalarType=T\u003e,T: Scalar\u003cRefType\u003c'a\u003e=T\u003e,{fn len(\u0026self)-\u003e usize {self.size-self.pos}}最后来个viewer引用的示例, concat_ws 实现： letviewers=columns.iter().map(|column|Vu8::try_create_viewer(column.column())).collect::\u003cResult\u003cVec\u003c_\u003e\u003e\u003e()?;letmutbuilder=MutableStringColumn::with_capacity(rows);letmutbuffer: Vec\u003cu8\u003e=Vec::with_capacity(32);(0..rows).for_each(|row|{buffer.clear();for(idx,viewer)inviewers.iter().enumerate(){if!viewer.null_at(row){ifidx\u003e0{buffer.extend_from_slice(sep);}buffer.extend_from_slice(viewer.value_at(row));}}builder.append_value(buffer.as_slice());});Ok(builder.to_column())","date":"2022-02-25","objectID":"/posts/%E7%B1%BB%E5%9E%8B%E4%BD%93%E6%93%8D%E5%9C%A8databend%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/:6:0","tags":null,"title":"类型体操在databend中的应用","uri":"/posts/%E7%B1%BB%E5%9E%8B%E4%BD%93%E6%93%8D%E5%9C%A8databend%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/"},{"categories":["database","databend"],"content":"过程宏 Tikv中引入了一个非常复杂的过程宏来生产向量化函数表达式，在databend中有过类似的尝试，但由于过程宏的实现过于复杂，自定义函数虽然代码量稍多，但会比较灵活，可读性以及维护性都比较好，所以我们这里没有使用过程宏。 ","date":"2022-02-25","objectID":"/posts/%E7%B1%BB%E5%9E%8B%E4%BD%93%E6%93%8D%E5%9C%A8databend%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/:7:0","tags":null,"title":"类型体操在databend中的应用","uri":"/posts/%E7%B1%BB%E5%9E%8B%E4%BD%93%E6%93%8D%E5%9C%A8databend%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/"},{"categories":["database","databend"],"content":"总结 经过type-exercise的改造后，聚合函数和标量函数的计算终于可以以非常精简的方式实现了，最后特别感谢迟先生的体操教程以及在这个过程中给出的建议，tql！！！ ","date":"2022-02-25","objectID":"/posts/%E7%B1%BB%E5%9E%8B%E4%BD%93%E6%93%8D%E5%9C%A8databend%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/:8:0","tags":null,"title":"类型体操在databend中的应用","uri":"/posts/%E7%B1%BB%E5%9E%8B%E4%BD%93%E6%93%8D%E5%9C%A8databend%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/"},{"categories":["Thinking"],"content":"知识沉淀 《如何高效学习》中提出过费曼学习法。费曼学习法也称“费曼定理”，很多人将其奉行为终极学习法。 费曼学习法整体来说可以简化为四个单词：Concept （概念）、Teach （教给别人）、Review （回顾）、Simplify （简化）。 前面第一步到第二步是一个被动学习转换为主动学习的过程，后面两步可以理解为复习消化的过程。 在《穷爸爸与富爸爸》 一书中，作者第一章节也提出了主动学习相比被动学习的好处： 写博客是需要花费不少精力的，学是一回事，写是一回事，教又是另外一回事。将自己学到新的知识或者体会到的新的思想观，经过自我消化整理后，用简练的文字和配图写成博文分享给大众。整个过程走下来，其实也走过了费曼学习法的四个环节。于人于己，我看到了撰写博文的好处，不仅仅传播了知识，也加深了自己掌握的知识沉淀。 ","date":"2022-01-02","objectID":"/posts/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%88%E5%BC%80%E5%A7%8B%E5%86%99%E5%8D%9A%E5%AE%A2%E4%BA%86/:1:0","tags":null,"title":"2022年，我为什么又开始写博客了","uri":"/posts/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%88%E5%BC%80%E5%A7%8B%E5%86%99%E5%8D%9A%E5%AE%A2%E4%BA%86/"},{"categories":["Thinking"],"content":"社区的交流讨论 个人在阅读上掌握的知识，在理解上可能带有个人的偏见，如果将学到的东西用偏见的思维积累下来，长期下来，可能会导致自己固步自封，对其他不一样的思想主观上有拒绝倾向。 将知识公开在博客，可以引起社区成员的关注，评论系统是一个非常好的交流方式，有利于纠正对事情不对的理解和偏见。 之前一直将一些技术杂七杂八地粘贴在个人的印象笔记中，现在觉得更多的东西应该沉淀到博客中反而更能引起大众的共鸣。 ","date":"2022-01-02","objectID":"/posts/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%88%E5%BC%80%E5%A7%8B%E5%86%99%E5%8D%9A%E5%AE%A2%E4%BA%86/:2:0","tags":null,"title":"2022年，我为什么又开始写博客了","uri":"/posts/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%88%E5%BC%80%E5%A7%8B%E5%86%99%E5%8D%9A%E5%AE%A2%E4%BA%86/"},{"categories":["Thinking"],"content":"从众心理 我非常佩服一些长期坚持写技术博客的博主，比如 阮一峰, 左耳朵耗子 等，还有我工作中的一些优秀的同事：drxp, xuanwo, codedump。在阅读他们的博客的时候，不仅仅可以看到他们对技术的思考，也有对生活的领悟。 现在我也有小孩了，假如我能将工作生活上的东西积累到博客中，孩子长大了或许能看到我的博客，也许能理解到当时的我在做什么，思考什么，虽然我那时候可能老了，但也算是一种时间上的慰藉吧，就像许飞的那首 父亲的散文诗. ","date":"2022-01-02","objectID":"/posts/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%88%E5%BC%80%E5%A7%8B%E5%86%99%E5%8D%9A%E5%AE%A2%E4%BA%86/:3:0","tags":null,"title":"2022年，我为什么又开始写博客了","uri":"/posts/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%88%E5%BC%80%E5%A7%8B%E5%86%99%E5%8D%9A%E5%AE%A2%E4%BA%86/"},{"categories":["Code"],"content":" 本文将介绍一下c++代码模板的小技巧 —– CRTP ","date":"2021-01-28","objectID":"/posts/c++%E4%BB%A3%E7%A0%81%E6%A8%A1%E6%9D%BF%E4%B9%8Bcrtp/:0:0","tags":["Template"],"title":"C++代码模板之CRTP","uri":"/posts/c++%E4%BB%A3%E7%A0%81%E6%A8%A1%E6%9D%BF%E4%B9%8Bcrtp/"},{"categories":["Code"],"content":"虚函数 在介绍 CRTP 之前，我们先来了解下虚函数。 虚函数是通过指向派生类的基类指针或引用，访问派生类中同名覆盖成员函数，从而实现了多态的特性。 一段简单的代码示例 class A { public: virtual void print() { std::cout \u003c\u003c \"Hello from A\" \u003c\u003c std::endl; } }; class B : public A { public: void print() override { std::cout \u003c\u003c \"Hello from B\" \u003c\u003c std::endl; } }; 虚函数实现了多态的特性，但是每次调用的时候都要对虚函数表进行 look-up, 所以开销不低，较之直接调用具体对象的方法，虚函数调用通常会慢一个数量级以上。在一些对性能敏感领域的软件系统中，比如OLAP数据库系统，需要对海量数据进行计算分析，虚函数的调用将会放大特别严重。 ","date":"2021-01-28","objectID":"/posts/c++%E4%BB%A3%E7%A0%81%E6%A8%A1%E6%9D%BF%E4%B9%8Bcrtp/:1:0","tags":["Template"],"title":"C++代码模板之CRTP","uri":"/posts/c++%E4%BB%A3%E7%A0%81%E6%A8%A1%E6%9D%BF%E4%B9%8Bcrtp/"},{"categories":["Code"],"content":"CRTP 奇异递归模板模式(Curiously Recurring Template Pattern，CRTP)，CRTP是C++模板编程时的一种常见技巧（idiom）：把派生类作为基类的模板参数。更一般地被称作F-bound polymorphism，是一类F 界量化。 ","date":"2021-01-28","objectID":"/posts/c++%E4%BB%A3%E7%A0%81%E6%A8%A1%E6%9D%BF%E4%B9%8Bcrtp/:2:0","tags":["Template"],"title":"C++代码模板之CRTP","uri":"/posts/c++%E4%BB%A3%E7%A0%81%E6%A8%A1%E6%9D%BF%E4%B9%8Bcrtp/"},{"categories":["Code"],"content":"CRTP 的基本范式 template \u003ctypename T\u003e class Base { ... }; class Derived : public Base\u003cDerived\u003e { ... }; 这样做的目的在于在基类中使用派生类的方法，从基类的角度来看，派生类也是一个基类，基类可以通过static_cast将其转为派生类，从而静态使用派生类的成员和方法，如下： template \u003ctypename T\u003e class Base { public: void doWhat() { T\u0026 derived = static_cast\u003cT\u0026\u003e(*this); // use derived... } }; ","date":"2021-01-28","objectID":"/posts/c++%E4%BB%A3%E7%A0%81%E6%A8%A1%E6%9D%BF%E4%B9%8Bcrtp/:2:1","tags":["Template"],"title":"C++代码模板之CRTP","uri":"/posts/c++%E4%BB%A3%E7%A0%81%E6%A8%A1%E6%9D%BF%E4%B9%8Bcrtp/"},{"categories":["Code"],"content":"静态动态 Andrei Alexandrescu在Modern C++ Design中称 CRTP 为静态多态（static polymorphism）。 相比于普通继承方式实现的多台，CRTP可以在编译器实现类型的绑定，这种方式实现了虚函数的效果，同时也避免了动态多态的代价。 ","date":"2021-01-28","objectID":"/posts/c++%E4%BB%A3%E7%A0%81%E6%A8%A1%E6%9D%BF%E4%B9%8Bcrtp/:2:2","tags":["Template"],"title":"C++代码模板之CRTP","uri":"/posts/c++%E4%BB%A3%E7%A0%81%E6%A8%A1%E6%9D%BF%E4%B9%8Bcrtp/"},{"categories":["Code"],"content":"权限控制 为了让基类能访问派生类的私有成员或方法，我们可以在派生类中和基类成为友元类。 friend class Base\u003cDerived\u003e; ","date":"2021-01-28","objectID":"/posts/c++%E4%BB%A3%E7%A0%81%E6%A8%A1%E6%9D%BF%E4%B9%8Bcrtp/:2:3","tags":["Template"],"title":"C++代码模板之CRTP","uri":"/posts/c++%E4%BB%A3%E7%A0%81%E6%A8%A1%E6%9D%BF%E4%B9%8Bcrtp/"},{"categories":["Code"],"content":"std::enable_shared_from_this 假如在c++中想要在一个已被shareptr管理的类型对象内获取并返回this，为了防止被管理的对象已被智能指针释放，而导致this成为悬空指针，可能会考虑以share_ptr的形式返回this指针，我们可以使用 std::enable_shared_from_this， 它本身就是一种CRTP在标准库中的实现 struct FOO: std::enable_shared_from_this\u003cFOO\u003e { std::shared_ptr\u003cFOO\u003e getptr() { return shared_from_this(); } }; ","date":"2021-01-28","objectID":"/posts/c++%E4%BB%A3%E7%A0%81%E6%A8%A1%E6%9D%BF%E4%B9%8Bcrtp/:2:4","tags":["Template"],"title":"C++代码模板之CRTP","uri":"/posts/c++%E4%BB%A3%E7%A0%81%E6%A8%A1%E6%9D%BF%E4%B9%8Bcrtp/"},{"categories":["Code"],"content":"CRTP 示例 (来自clickhouse源码) /// Implement method to obtain an address of 'add' function. template \u003ctypename Derived\u003e class IAggregateFunctionHelper : public IAggregateFunction { private: static void addFree(const IAggregateFunction * that, AggregateDataPtr place, const IColumn ** columns, size_t row_num, Arena * arena) { static_cast\u003cconst Derived \u0026\u003e(*that).add(place, columns, row_num, arena); } public: IAggregateFunctionHelper(const DataTypes \u0026 argument_types_, const Array \u0026 parameters_) : IAggregateFunction(argument_types_, parameters_) {} AddFunc getAddressOfAddFunction() const override { return \u0026addFree; } void addBatch(size_t batch_size, AggregateDataPtr * places, size_t place_offset, const IColumn ** columns, Arena * arena) const override { for (size_t i = 0; i \u003c batch_size; ++i) static_cast\u003cconst Derived *\u003e(this)-\u003eadd(places[i] + place_offset, columns, i, arena); } void addBatchSinglePlace(size_t batch_size, AggregateDataPtr place, const IColumn ** columns, Arena * arena) const override { for (size_t i = 0; i \u003c batch_size; ++i) static_cast\u003cconst Derived *\u003e(this)-\u003eadd(place, columns, i, arena); } void addBatchArray( size_t batch_size, AggregateDataPtr * places, size_t place_offset, const IColumn ** columns, const UInt64 * offsets, Arena * arena) const override { size_t current_offset = 0; for (size_t i = 0; i \u003c batch_size; ++i) { size_t next_offset = offsets[i]; for (size_t j = current_offset; j \u003c next_offset; ++j) static_cast\u003cconst Derived *\u003e(this)-\u003eadd(places[i] + place_offset, columns, j, arena); current_offset = next_offset; } } }; ","date":"2021-01-28","objectID":"/posts/c++%E4%BB%A3%E7%A0%81%E6%A8%A1%E6%9D%BF%E4%B9%8Bcrtp/:2:5","tags":["Template"],"title":"C++代码模板之CRTP","uri":"/posts/c++%E4%BB%A3%E7%A0%81%E6%A8%A1%E6%9D%BF%E4%B9%8Bcrtp/"},{"categories":["Code"],"content":"总结 如果想在编译期确定通过基类来得到派生类的行为，CRTP便是一种绝佳的选择， :) ","date":"2021-01-28","objectID":"/posts/c++%E4%BB%A3%E7%A0%81%E6%A8%A1%E6%9D%BF%E4%B9%8Bcrtp/:3:0","tags":["Template"],"title":"C++代码模板之CRTP","uri":"/posts/c++%E4%BB%A3%E7%A0%81%E6%A8%A1%E6%9D%BF%E4%B9%8Bcrtp/"},{"categories":null,"content":"中年90后程序员，江西赣州人士，毕业于中山大学。 常用网名sundy-li, 曾就职于虎牙 \u0026 bigo，目前在datafuselabs 工作，专注研究实时云原生数仓，GitHub 远程工作中。 博客模板来自于Hugo 主题 LoveIt ","date":"2021-01-02","objectID":"/about/:0:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":["ClickHouse"],"content":"前言 如果要按工具链友好度评选一门最佳语言，我会首选 Golang，因为它有一系列的go tool工具，面向开发者非常友好。 其中go tool pprof 结合 go-torch ，能快速得出go程序的火焰图。在Linux系统中， perf 工具也十分强大，里面有各种子工具分析系统级进程的性能。perf 通常结合 FlameGraph 可以生成不错的火焰图。在一次偶然的机会中，笔者接触到了 SpeedScope，本文以调优 ClickHouse 为例子，介绍一下 SpeedScope 工具的使用。 ","date":"2020-09-11","objectID":"/posts/%E4%BD%BF%E7%94%A8speedscope%E4%BD%9C%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/:1:0","tags":["profile","ClickHouse"],"title":"使用SpeedScope作性能分析","uri":"/posts/%E4%BD%BF%E7%94%A8speedscope%E4%BD%9C%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"categories":["ClickHouse"],"content":"SpeedScope 介绍 SpeedScope 是一款在线的 flamegraph 可视化工具。它可以和多个编程语言相结合，也可以将 perf report的结果拖拽到网站里面在线分析。 ","date":"2020-09-11","objectID":"/posts/%E4%BD%BF%E7%94%A8speedscope%E4%BD%9C%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/:2:0","tags":["profile","ClickHouse"],"title":"使用SpeedScope作性能分析","uri":"/posts/%E4%BD%BF%E7%94%A8speedscope%E4%BD%9C%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"categories":["ClickHouse"],"content":"安装(可选) speedscope 是 nodejs 编写的，安装这个工具是可选的，安装后可以基于本地生成可视化性能图。 sudo npm install -g speedscope ","date":"2020-09-11","objectID":"/posts/%E4%BD%BF%E7%94%A8speedscope%E4%BD%9C%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/:3:0","tags":["profile","ClickHouse"],"title":"使用SpeedScope作性能分析","uri":"/posts/%E4%BD%BF%E7%94%A8speedscope%E4%BD%9C%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"categories":["ClickHouse"],"content":"使用 我们在ClickHouse 里面执行一个”简单“且“复杂“的SQL的SQL，计算十亿个数的平均值。 selectavg(number)fromnumbers(1000000000);使用 perf 工具\"记录\"程序性能, 记录10s perf record -a -F 999 -g -p 17562 sleep 10 如果安装了 speedscope 工具， 我们可以直接在shell中调用 perf script -i perf.data | speedscope - 这个命令会生成一个静态html文件，本地的话可以直接打开进入可视化页面。但笔者并没有这样做，因为笔者在公司服务器作了perf记录，静态html其实是生成了一个到npm modules的跳转，无法拉到本地的浏览器打开。 不过没事，我们可以将生成script拉到本地后,拖拽到 https://www.speedscope.app/ 中打开。 perf script -i perf.data \u003e profile.linux-perf.txt 进入页面后，我们可以非常直观地看到各个时间轴上的调用开销时间占用情况。上面截图中，可以反映出，10s内的采样中，有5.99s 耗在 AggregateFunctionAvg 函数中， 有 2.14s 耗在 NumbersSource::generate 生成中。 使用 Perf 的方式，我们可以很直观得看到性能图，但我们并不能针对特定的SQL进行profile，下面介绍下 clickhouse-speedscope 如何针对特定SQL进行profile。 ","date":"2020-09-11","objectID":"/posts/%E4%BD%BF%E7%94%A8speedscope%E4%BD%9C%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/:4:0","tags":["profile","ClickHouse"],"title":"使用SpeedScope作性能分析","uri":"/posts/%E4%BD%BF%E7%94%A8speedscope%E4%BD%9C%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"categories":["ClickHouse"],"content":"clickhouse-speedscope 第一次接触到SpeedScope，是无意中看到了 clickhouse-speedscope 项目。这个项目巧妙地利用了 clickhouse的系统表 system.trace_log 进行采样。 注意：要使用system.trace_log ，必须安装好 clickhouse-common-static-dbg 库, 并且开启 allow_introspection_functions等参数，更多配置参数参考这里. Clone clickhouse-speedscope 后，发现代码非常简单，核心就一个python文件，监控了http端口进行处理请求的返回。 pip安装好依赖库后，我们首先开启下端口监听 8089端口，同时会转发 query_id 查询 服务器域名为ck001 的clickhouse-server python main.py --ch-host ck001 --proxy-port 8089 然后，我们在 clickhouse 层执行SQL，这里为了方便快速获取 query-id ，我们打开logs输出，以及打开函数抽样trace的开关 ubuntu:)setsend_logs_level='trace';SETsend_logs_level='trace'Ok.0rowsinset.Elapsed:0.021sec.ubuntu:)setallow_introspection_functions=0;SETallow_introspection_functions=0[ubuntu]2020.09.1123:02:13.061146[17134]{d4a0c7af-c836-4360-8264-926f634e1d94}\u003cDebug\u003eexecuteQuery:(from127.0.0.1:52012)SETallow_introspection_functions=0[ubuntu]2020.09.1123:02:13.061471[17134]{d4a0c7af-c836-4360-8264-926f634e1d94}\u003cDebug\u003eMemoryTracker:Peakmemoryusage(forquery):0.00B.Ok.0rowsinset.Elapsed:0.042sec. 这里我们就可以看到具体日志了，然后我们继续执行那个”简单“且“复杂“的SQL （线上40core 128G服务器） ubuntu:)selectavg(number)fromnumbers(1000000000);SELECTavg(number)FROMnumbers(1000000000)[ubuntu]2020.09.1123:03:58.739452[17134]{6e4b5384-39c5-4d02-9383-e312e92f2681}\u003cDebug\u003eexecuteQuery:(from127.0.0.1:52012)SELECTavg(number)FROMnumbers(1000000000)→Progress:0.00rows,0.00B(0.00rows/s.,0.00B/s.)[ubuntu]2020.09.1123:03:58.739624[17134]{6e4b5384-39c5-4d02-9383-e312e92f2681}\u003cTrace\u003eAccessRightsContext(default):Accessgranted:numbers()ON*.*[ubuntu]2020.09.1123:03:58.739649[17134]{6e4b5384-39c5-4d02-9383-e312e92f2681}\u003cTrace\u003eAccessRightsContext(default):Accessgranted:numbers()ON*.*[ubuntu]2020.09.1123:03:58.747053[17134]{6e4b5384-39c5-4d02-9383-e312e92f2681}\u003cTrace\u003eInterpreterSelectQuery:FetchColumns-\u003eComplete[ubuntu]2020.09.1123:03:58.747139[17134]{6e4b5384-39c5-4d02-9383-e312e92f2681}\u003cDebug\u003eexecuteQuery:Querypipeline:ExpressionExpressionAggregatingConcatExpressionTreeExecutor↘Progress:75.96millionrows,607.65MB(699.98millionrows/s.,5.60GB/s.)7%[ubuntu]2020.09.1123:03:58.747262[28335]{6e4b5384-39c5-4d02-9383-e312e92f2681}\u003cTrace\u003eAggregator:Aggregating[ubuntu]2020.09.1123:03:58.747377[28335]{6e4b5384-39c5-4d02-9383-e312e92f2681}\u003cTrace\u003eAggregator:Aggregationmethod:without_key┌─avg(number)─┐│499999999.5│└─────────────┘↖Progress:951.06millionrows,7.61GB(746.09millionrows/s.,5.97GB/s.)█████████████████████████████████████████████████████▎94%[ubuntu]2020.09.1123:04:00.013119[28335]{6e4b5384-39c5-4d02-9383-e312e92f2681}\u003cTrace\u003eAggregator:Aggregated.1000000000to1rows(from7629.395MiB)in1.266sec.(790016853.437rows/sec.,6027.350MiB/sec.)[ubuntu]2020.09.1123:04:00.013271[28335]{6e4b5384-39c5-4d02-9383-e312e92f2681}\u003cTrace\u003eAggregator:Mergingaggregateddata[ubuntu]2020.09.1123:04:00.013537[17134]{6e4b5384-39c5-4d02-9383-e312e92f2681}\u003cInformation\u003eexecuteQuery:Read1000013824rows,7.45GiBin1.274sec.,784921953rows/sec.,5.85GiB/sec.[ubuntu]2020.09.1123:04:00.013576[17134]{6e4b5384-39c5-4d02-9383-e312e92f2681}\u003cDebug\u003eMemoryTracker:Peakmemoryusage(forquery):137.09KiB.1rowsinset.Elapsed:1.275sec.Processed1.00billionrows,8.00GB(784.34millionrows/s.,6.27GB/s.) 拿到了query-id，之后，我们通过 curl 可以直接获取到traceing的结果。 curl 'http://localhost:8089/query?query_id=fe9078cd-9570-4895-b328-4728a097306a' | speedscope - 如果没有装 speedscope， 也可以重定向到一个文件中，然后拖拽到 https://www.speedscope.app/ 中。 ","date":"2020-09-11","objectID":"/posts/%E4%BD%BF%E7%94%A8speedscope%E4%BD%9C%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/:5:0","tags":["profile","ClickHouse"],"title":"使用SpeedScope作性能分析","uri":"/posts/%E4%BD%BF%E7%94%A8speedscope%E4%BD%9C%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"categories":["ClickHouse"],"content":"总结 使用 speedscope， 我们在本地就可以很方便地对 ClickHouse 进行远程 profile，去试试吧！ ","date":"2020-09-11","objectID":"/posts/%E4%BD%BF%E7%94%A8speedscope%E4%BD%9C%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/:6:0","tags":["profile","ClickHouse"],"title":"使用SpeedScope作性能分析","uri":"/posts/%E4%BD%BF%E7%94%A8speedscope%E4%BD%9C%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"}]